{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0' 'index' 'loan_amnt' 'int_rate' 'installment'\n",
      " 'home_ownership' 'annual_inc' 'verification_status' 'loan_status'\n",
      " 'pymnt_plan' 'dti' 'delinq_2yrs' 'inq_last_6mths' 'open_acc' 'pub_rec'\n",
      " 'revol_bal' 'total_acc' 'initial_list_status' 'out_prncp' 'out_prncp_inv'\n",
      " 'total_pymnt' 'total_pymnt_inv' 'total_rec_prncp' 'total_rec_int'\n",
      " 'total_rec_late_fee' 'recoveries' 'collection_recovery_fee'\n",
      " 'last_pymnt_amnt' 'collections_12_mths_ex_med' 'policy_code'\n",
      " 'application_type' 'acc_now_delinq' 'tot_coll_amt' 'tot_cur_bal'\n",
      " 'open_acc_6m' 'open_act_il' 'open_il_12m' 'open_il_24m'\n",
      " 'mths_since_rcnt_il' 'total_bal_il' 'il_util' 'open_rv_12m' 'open_rv_24m'\n",
      " 'max_bal_bc' 'all_util' 'total_rev_hi_lim' 'inq_fi' 'total_cu_tl'\n",
      " 'inq_last_12m' 'acc_open_past_24mths' 'avg_cur_bal' 'bc_open_to_buy'\n",
      " 'bc_util' 'chargeoff_within_12_mths' 'delinq_amnt' 'mo_sin_old_il_acct'\n",
      " 'mo_sin_old_rev_tl_op' 'mo_sin_rcnt_rev_tl_op' 'mo_sin_rcnt_tl'\n",
      " 'mort_acc' 'mths_since_recent_bc' 'mths_since_recent_inq'\n",
      " 'num_accts_ever_120_pd' 'num_actv_bc_tl' 'num_actv_rev_tl' 'num_bc_sats'\n",
      " 'num_bc_tl' 'num_il_tl' 'num_op_rev_tl' 'num_rev_accts'\n",
      " 'num_rev_tl_bal_gt_0' 'num_sats' 'num_tl_120dpd_2m' 'num_tl_30dpd'\n",
      " 'num_tl_90g_dpd_24m' 'num_tl_op_past_12m' 'pct_tl_nvr_dlq'\n",
      " 'percent_bc_gt_75' 'pub_rec_bankruptcies' 'tax_liens' 'tot_hi_cred_lim'\n",
      " 'total_bal_ex_mort' 'total_bc_limit' 'total_il_high_credit_limit'\n",
      " 'hardship_flag' 'debt_settlement_flag']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert categorical data to numeric on training data, feature and target\n",
    "# X_2019 = train_df.drop(\"loan_status\", axis=1)\n",
    "# X_2019 = pd.get_dummies(X_2019)\n",
    "\n",
    "# df2 = train_df.copy()\n",
    "\n",
    "# df2['loan_status'] = pd.get_dummies((df2['loan_status']))\n",
    "# from pandas import DataFrame\n",
    "# y_2019 = DataFrame(df2[\"loan_status\"])\n",
    "\n",
    "X_2019 = train_df.drop(\"loan_status\", axis=1)\n",
    "X_2019 = pd.get_dummies(X_2019)\n",
    "\n",
    "# df2 = train_df.copy()\n",
    "\n",
    "df2['loan_status'] = pd.get_dummies((train_df['loan_status']))\n",
    "from pandas import DataFrame\n",
    "y_2019 = DataFrame(df2[\"loan_status\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0' 'index' 'loan_amnt' 'int_rate' 'installment' 'annual_inc'\n",
      " 'dti' 'delinq_2yrs' 'inq_last_6mths' 'open_acc' 'pub_rec' 'revol_bal'\n",
      " 'total_acc' 'out_prncp' 'out_prncp_inv' 'total_pymnt' 'total_pymnt_inv'\n",
      " 'total_rec_prncp' 'total_rec_int' 'total_rec_late_fee' 'recoveries'\n",
      " 'collection_recovery_fee' 'last_pymnt_amnt' 'collections_12_mths_ex_med'\n",
      " 'policy_code' 'acc_now_delinq' 'tot_coll_amt' 'tot_cur_bal' 'open_acc_6m'\n",
      " 'open_act_il' 'open_il_12m' 'open_il_24m' 'mths_since_rcnt_il'\n",
      " 'total_bal_il' 'il_util' 'open_rv_12m' 'open_rv_24m' 'max_bal_bc'\n",
      " 'all_util' 'total_rev_hi_lim' 'inq_fi' 'total_cu_tl' 'inq_last_12m'\n",
      " 'acc_open_past_24mths' 'avg_cur_bal' 'bc_open_to_buy' 'bc_util'\n",
      " 'chargeoff_within_12_mths' 'delinq_amnt' 'mo_sin_old_il_acct'\n",
      " 'mo_sin_old_rev_tl_op' 'mo_sin_rcnt_rev_tl_op' 'mo_sin_rcnt_tl'\n",
      " 'mort_acc' 'mths_since_recent_bc' 'mths_since_recent_inq'\n",
      " 'num_accts_ever_120_pd' 'num_actv_bc_tl' 'num_actv_rev_tl' 'num_bc_sats'\n",
      " 'num_bc_tl' 'num_il_tl' 'num_op_rev_tl' 'num_rev_accts'\n",
      " 'num_rev_tl_bal_gt_0' 'num_sats' 'num_tl_120dpd_2m' 'num_tl_30dpd'\n",
      " 'num_tl_90g_dpd_24m' 'num_tl_op_past_12m' 'pct_tl_nvr_dlq'\n",
      " 'percent_bc_gt_75' 'pub_rec_bankruptcies' 'tax_liens' 'tot_hi_cred_lim'\n",
      " 'total_bal_ex_mort' 'total_bc_limit' 'total_il_high_credit_limit'\n",
      " 'home_ownership_ANY' 'home_ownership_MORTGAGE' 'home_ownership_OWN'\n",
      " 'home_ownership_RENT' 'verification_status_Not Verified'\n",
      " 'verification_status_Source Verified' 'verification_status_Verified'\n",
      " 'pymnt_plan_n' 'initial_list_status_f' 'initial_list_status_w'\n",
      " 'application_type_Individual' 'application_type_Joint App'\n",
      " 'hardship_flag_N' 'hardship_flag_Y' 'debt_settlement_flag_N'\n",
      " 'debt_settlement_flag_Y']\n"
     ]
    }
   ],
   "source": [
    "# print(train_df['loan_status'])\n",
    "print(X_2019.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0              6090\n",
       "1              6090\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2019.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert categorical data to numeric on testing data\n",
    "# X_2020test = pd.get_dummies(test_df.drop('loan_status', axis=1))\n",
    "\n",
    "# # Separate target feature for testing data\n",
    "# y_2020test = test_df.loc[:, 'loan_status']\n",
    "\n",
    "\n",
    "# Convert categorical data to numeric on training data, feature and target\n",
    "X_2020test = test_df.drop(\"loan_status\", axis=1)\n",
    "X_2020test = pd.get_dummies(X_2020test)\n",
    "\n",
    "# df2 = train_df.copy()\n",
    "\n",
    "df2['loan_status'] = pd.get_dummies((test_df['loan_status']))\n",
    "from pandas import DataFrame\n",
    "y_2020test = DataFrame(df2[\"loan_status\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing dummy variables to testing set\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( X_2019.columns ) - set( X_2020test.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    X_2020test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "X_2020test = X_2020test[X_2019.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0.0            2351\n",
       "1.0            2351\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2020test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2019, y_2019, random_state=1)\n",
    "Counter(y_train)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model 1 : Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertogonzalez/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/albertogonzalez/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) our model by using the training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6535303776683087\n",
      "Testing Data Score: 0.6440065681444992\n"
     ]
    }
   ],
   "source": [
    "# Validate the model by using the test data\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscale/Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores and classication report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rinse and Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model 2 : RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unscaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-e2489e3aa227>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.7937602627257799\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on unscaled data and print the model score\n",
    "# Fit random forest and get training and testing score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train, y_train)\n",
    "print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.81      0.77      0.79      1546\n",
      "    low_risk       0.77      0.82      0.80      1499\n",
      "\n",
      "    accuracy                           0.79      3045\n",
      "   macro avg       0.79      0.79      0.79      3045\n",
      "weighted avg       0.79      0.79      0.79      3045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"high_risk\", \"low_risk\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-7461f73be72c>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.7937602627257799\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "# Fit random forest and get training and testing score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.81      0.77      0.79      1546\n",
      "    low_risk       0.77      0.82      0.80      1499\n",
      "\n",
      "    accuracy                           0.79      3045\n",
      "   macro avg       0.79      0.79      0.79      3045\n",
      "weighted avg       0.79      0.79      0.79      3045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"high_risk\", \"low_risk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86884072, -0.86884072,  0.26219508, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [-0.97142543, -0.97142543,  0.75296671, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [-1.77412602, -1.77412602,  1.07196827, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       ...,\n",
       "       [ 0.5308302 ,  0.5308302 , -0.52303953, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [ 0.78356135,  0.78356135,  0.26219508, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [ 1.02208108,  1.02208108, -0.71934818, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the models and save the best one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
